{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explique la diferencia entre descenso de gradiente, descenso de gradiente por mini batches y descenso de\n",
    "gradiente estocástico. Asegúrese de mencionar las ventajas y desventajas de cada enfoque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrar a detalle entre los distintos tipos de descenso de gradiente, hay que definir el concepto del descenso de gradiente. Este es un algoritmo de optimización iterativo que se utiliza para encontrar el punto mínimo de la función de costo.\n",
    "\n",
    "La pendiente o gradiente es la derivada de primer orden de la función en el punto actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso de Gradiente:\n",
    "Este utiliza todo el conjunto de datos en cada iteración para calcular el gradiente de la función de costo.\n",
    "$$\\frac{∂Costo}{∂w} = \\frac{1}{N}\\sum_{i=1}^{N}  \\frac{∂Costo^{(i)}}{∂w}$$\n",
    "\n",
    "* Ventajas:\n",
    "    * El gráfico resultante es bastante uniforme debido a que se utiliza el promedio \n",
    "\n",
    "* Desventajas:\n",
    "    * Es muy costoso en datasets grandes\n",
    "    * No escala bien con datos masivos\n",
    "    * Se puede quedar atascado en mínimos locales en problemas no convexos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso de Gradiente Estocástico\n",
    "Se utiliza una muestra aleatoria en cada iteración.\n",
    "$$\\frac{∂Costo}{∂w} = \\frac{∂Costo^{(i)}}{∂w}\\text{, para una muestra } i \\text{ aleatoria}$$ \n",
    "\n",
    "* Ventajas:\n",
    "    * Cuando se trabaja con datasets más grandes, el costo disminuyirá.\n",
    "* Desventajas:\n",
    "    * Este es sensible al escalamiento de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descenso de Gradiente por mini batches:\n",
    "Este utiliza únicamente un subconkjunto de k muestras en cada paso. Se utiliza un conjunto de una cantidad fija de muestras de entrenamiento que es menor que el conjunto de datos real.\n",
    "$$\\frac{∂Costo}{∂w} = \\frac{1}{k}\\sum_{i=1}^{k}  \\frac{∂Costo^{(i)}}{∂w}$$\n",
    "\n",
    "* Ventajas:\n",
    "    * Aprovecha la vectorización para cálculos paralelos\n",
    "    * Tiene un balance entre estabilidad y eficiencia\n",
    "* Desventajas:\n",
    "    * Aún puede necesitar ajuste de la tasa de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare y contraste técnicas de extracción de features (feature extraction) y selección de features (feature\n",
    "selection) en machine learning. De ejemplos de escenarios donde cada técnica sería más apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Se transforman las features originales en nuevas features, disminuyendo la dimensión pero siempre manteniendo información relevante.\n",
    "##### Técnicas:\n",
    "* PCA (Principle Componemts Analysis):\n",
    "    * Se utilizan los datos originales como input y encontrar una combinación de las features que brinde un resumen de todos los datos. \n",
    "* ICA (Independent Component Analysis)\n",
    "##### Ventajas:\n",
    "* El dataset es menos complejo\n",
    "* Requiere menos espacio y menos tiempo de computación\n",
    "* Hay menos chances de causar ```overfitting``` en el modelo\n",
    "##### Desventajas:\n",
    "* El dataset es menos complejo\n",
    "* Requiere menos espacio y menos tiempo de computación\n",
    "* Hay menos chances de causar ```overfitting``` en el modelo\n",
    "\n",
    "\n",
    "### Feature Selection\n",
    "Como dice el nombre, se trata de seleccionar las columnas relevantes para el estudio que se quiere llegar a hacer. \n",
    "##### Técnicas:\n",
    "* a\n",
    "* a\n",
    "##### Ventajas:\n",
    "* El dataset es menos complejo\n",
    "* Requiere menos espacio y menos tiempo de computación\n",
    "* Hay menos chances de causar ```overfitting``` en el modelo\n",
    "##### Desventajas:\n",
    "* El dataset es menos complejo\n",
    "* Requiere menos espacio y menos tiempo de computación\n",
    "* Hay menos chances de causar ```overfitting``` en el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Describa la arquitectura y el funcionamiento de un perceptrón de una sola capa (un tipo de red neuronal sin\n",
    "backpropagation). Explique cómo aprende y la forma en la que actualiza sus parámetros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
